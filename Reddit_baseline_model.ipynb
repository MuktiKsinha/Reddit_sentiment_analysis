{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c261d74e-2340-4a45-9702-1051ee43f0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "I#nstall necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.featur# necessary librarieries\n",
    "e_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split,cross_val_predict,StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b64a113-0afb-4124-9d4b-83036170f524",
   "metadata": {},
   "source": [
    "#1.## check the mlflow server---Testing\n",
    "mlflow.set_tracking_uri(\"http://ec2-13-62-127-52.eu-north-1.compute.amazonaws.com:5000/\")\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"param1\", 15)\n",
    "    mlflow.log_metric(\"metric1\", 0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e975c6f3-57eb-4805-bdd0-58081c4ce1ba",
   "metadata": {},
   "source": [
    "# run the base line model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40fe763-8267-4c9e-8bb1-a36506522bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/Himanshu-1703/reddit-sentiment-analysis/refs/heads/main/data/reddit.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404f9eed-e8b7-45c4-b7b2-78b760fd13d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c905c9-31ae-4689-99b3-7de9448d309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a35f57-56f4-49ea-9296-6bd3d8e27896",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df['clean_comment'].str.strip() == '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5506254-d511-4819-bea7-118751a55311",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure necessary nltk data is downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af04917-3f86-4b4a-919a-165a891fd21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the preprocessing function\n",
    "\n",
    "def preprocess_comment(comment):\n",
    "    # convert to lower case\n",
    "    comment = comment.lower()\n",
    "\n",
    "    #remove the trailing and leading space\n",
    "    comment = comment.strip()\n",
    "\n",
    "    #remove the newline characters\n",
    "    comment = re.sub('\\n',' ',comment)\n",
    "\n",
    "    #remove the non-alphanumeric character, except punctuations\n",
    "    comment = re.sub(r'[^A-Za-z0-9\\s!?.,]', '', comment)\n",
    "\n",
    "    #remove the stopwords but retain the important ones for sentiment analysis\n",
    "    stop_words = set(stopwords.words('english')) -{'not','but','however','no','yet'}\n",
    "    comment = ' '.join([word for word in comment.split() if word.lower() not in stop_words])\n",
    "\n",
    "    #lemmatize the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    comment = ' '.join([lemmatizer.lemmatize(word) for word in comment.split()])\n",
    "\n",
    "    return comment\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6047b572-734b-45a0-ad19-690e071b89d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the preprocessing function to clean clean_comment\n",
    "df['clean_comment']= df['clean_comment'].apply(preprocess_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e65c17-7136-40e4-8391-a8f884a8487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a055d0de-8f41-4bed-81ca-b8074131b5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply BOW\n",
    "vectorizer = CountVectorizer(max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094d1671-3192-4b98-b1a3-fc07d2ab791c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(df['clean_comment']).toarray()\n",
    "y = df['category'] # Assuming 'sentiment' is the target variable (0 or 1 for binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf223af-2f59-46ba-93c4-aafbfce061e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70521c16-b371-4f58-be45-11c0abf961a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3148c429-efce-490f-99ad-b8e2bf784d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 : Set up the mlflow tracking server \n",
    "mlflow.set_tracking_uri(\"http://ec2-13-62-127-52.eu-north-1.compute.amazonaws.com:5000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e210ede3-ad08-431d-bcfa-4e13212126e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"RF Baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471fdb75-0e34-4b7a-80cb-e98222ce5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# design the base line model\n",
    "#step 1: split the data into traing and testing sets(80% train, 20% test)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42,stratify=y) #stratify=y for imbalanced dataset\n",
    "\n",
    "#step 2: Define and train a Random Forest baseline model using a  simpke test train split\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    #log the description of the run\n",
    "    mlflow.set_tag(\"mlflow.runName\", \"Randomforest_baseline_TrainTestSplit\")\n",
    "    mlflow.set_tag(\"experiment_type\", \"Baseline\")\n",
    "    mlflow.set_tag(\"model_type\",\"RandomForestClassifier\")\n",
    "\n",
    "    # Add a description\n",
    "    mlflow.set_tag(\"description\", \"Baseline RandomForest model for sentiment analysis using Bag of Words (BoW) with a simple train-test split\")\n",
    "\n",
    "    #log parameters for the vectorizers\n",
    "    mlflow.log_param(\"vectorizer_type\", \"CountVectorizer\")\n",
    "    mlflow.log_param(\"vactorizer_max_features\",vectorizer.max_features)\n",
    "\n",
    "    #log Random Forest Classifier\n",
    "    n_estimators = 150\n",
    "    max_depth = 15\n",
    "\n",
    "    mlflow.log_param(\"n_estimators\",n_estimators)\n",
    "    mlflow.log_param(\"max_depth\",max_depth)\n",
    "\n",
    "    #initialize and train the model\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators,max_depth=max_depth,random_state=42)\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    # make the prediction\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # log metrics \n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    mlflow.log_metric(\"accuracy\",accuracy)\n",
    "\n",
    "    # classification report for each metric and log in mlflow\n",
    "\n",
    "    classification_rep = classification_report(y_test,y_pred,output_dict=True)\n",
    "\n",
    "    for label,metrics in classification_rep,items():\n",
    "        if isinstance(metrics,dict):\n",
    "            for metrics,value in metrics.item():   ###for precisison ,recall ,f1 score etc\n",
    "                mlflow.log_metric(f\"{label}_{metrics}\",value)\n",
    "\n",
    "    # confusion metrics plot\n",
    "    conf_matrix = Confusion_matrix(y_test,y_pred)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(conf_matrix,annot=True, fmt=\"d\",cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "\n",
    "    #save and log the confusion matrix plot\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    mlflow.log_artifact('confusion_matrix.png')\n",
    "\n",
    "    #log the model\n",
    "    mlflow.sklearn.log_model(model,\"random_forest_model\")\n",
    "\n",
    "    # Optionally log the dataset itself (if it's small enough)\n",
    "    df.to_csv(\"dataset.csv\", index=False)\n",
    "    mlflow.log_artifact(\"dataset.csv\")\n",
    "\n",
    "# Display final accuracy\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a492b347-7a33-49a8-b9ba-c07c5eef9596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get it configured to S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216e0492-d312-446e-87bc-c737e0fb4dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
